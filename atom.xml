<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://LittleFish0820.github.io</id>
    <title>小鱼儿</title>
    <updated>2022-08-29T02:09:37.679Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://LittleFish0820.github.io"/>
    <link rel="self" href="https://LittleFish0820.github.io/atom.xml"/>
    <subtitle>鱼戏莲叶间</subtitle>
    <logo>https://LittleFish0820.github.io/images/avatar.png</logo>
    <icon>https://LittleFish0820.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, 小鱼儿</rights>
    <entry>
        <title type="html"><![CDATA[Flink安装]]></title>
        <id>https://LittleFish0820.github.io/post/flink_install/</id>
        <link href="https://LittleFish0820.github.io/post/flink_install/">
        </link>
        <updated>2022-08-29T02:06:12.000Z</updated>
        <summary type="html"><![CDATA[<p></p>
<p>Flink单机、集群安装，及作业提交测试。</p>
]]></summary>
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC">
<li><a href="#local%E6%A8%A1%E5%BC%8F">Local模式</a></li>
<li><a href="#%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8">集群启动</a>
<ul>
<li><a href="#%E4%BF%AE%E6%94%B9%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE">修改集群配置</a></li>
<li><a href="#%E5%88%86%E5%8F%91">分发</a></li>
<li><a href="#%E5%90%AF%E5%8A%A8">启动</a></li>
<li><a href="#%E5%81%9C%E6%AD%A2">停止</a></li>
</ul>
</li>
<li><a href="#%E6%8F%90%E4%BA%A4%E4%BD%9C%E4%B8%9A%E6%B5%8B%E8%AF%95">提交作业测试</a>
<ul>
<li><a href="#pomxml">pom.xml</a></li>
<li><a href="#batchwordcountjava">BatchWordCount.java</a></li>
<li><a href="#boundedstreamwordcountjava">BoundedStreamWordCount.java</a></li>
<li><a href="#streamwordcountjava">StreamWordCount.java</a></li>
<li><a href="#%E6%89%93%E5%8C%85%E5%B9%B6%E6%8F%90%E4%BA%A4">打包并提交</a></li>
</ul>
</li>
<li><a href="#%E5%8F%96%E6%B6%88%E4%BB%BB%E5%8A%A1">取消任务</a></li>
</ul>
</p>
<p>Flink单机、集群安装，及作业提交测试。</p>
<!-- more -->
<h1 id="local模式">Local模式</h1>
<pre><code class="language-bash">tar -zxvf flink-1.13.0-bin-scala_2.12.tgz -C /opt/module/
</code></pre>
<pre><code class="language-bash">bin/start-cluster.sh
</code></pre>
<p>访问WebUI http://hadoop102:8081</p>
<hr>
<h1 id="集群启动">集群启动</h1>
<h2 id="修改集群配置">修改集群配置</h2>
<pre><code class="language-bash">cd conf/
vim flink-conf.yaml
jobmanager.rpc.address: hadoop102
</code></pre>
<pre><code class="language-bash">vim workers
hadoop103
hadoop104
</code></pre>
<h2 id="分发">分发</h2>
<pre><code class="language-bash">xsync /opt/module/flink
</code></pre>
<h2 id="启动">启动</h2>
<pre><code class="language-bash">./bin/start-cluster.sh
</code></pre>
<p>访问WebUI http://hadoop102:8081</p>
<h2 id="停止">停止</h2>
<pre><code class="language-bash">./bin/stop-cluster.sh
</code></pre>
<hr>
<h1 id="提交作业测试">提交作业测试</h1>
<h2 id="pomxml">pom.xml</h2>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.fish&lt;/groupId&gt;
    &lt;artifactId&gt;FlinkTutorial&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;

    &lt;properties&gt;
        &lt;flink.version&gt;1.13.0&lt;/flink.version&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
        &lt;scala.binary.version&gt;2.12&lt;/scala.binary.version&gt;
        &lt;slf4j.version&gt;1.7.30&lt;/slf4j.version&gt;
        &lt;maven.compiler.source&gt;8&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;8&lt;/maven.compiler.target&gt;
    &lt;/properties&gt;

    &lt;dependencies&gt;
        &lt;!-- 引入 Flink 相关依赖--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-java&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-streaming-java_${scala.binary.version}&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-clients_${scala.binary.version}&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;!-- 引入日志管理相关依赖--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
            &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;
            &lt;version&gt;${slf4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
            &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;
            &lt;version&gt;${slf4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j-to-slf4j&lt;/artifactId&gt;
            &lt;version&gt;2.14.0&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.0.0&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;descriptorRefs&gt;
                        34
                        &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;
                    &lt;/descriptorRefs&gt;
                &lt;/configuration&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;id&gt;make-assembly&lt;/id&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;single&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;
</code></pre>
<h2 id="batchwordcountjava">BatchWordCount.java</h2>
<p>批处理 DataSet API</p>
<pre><code class="language-java">package com.fish.wc;

import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.api.java.ExecutionEnvironment;
import org.apache.flink.api.java.operators.AggregateOperator;
import org.apache.flink.api.java.operators.DataSource;
import org.apache.flink.api.java.operators.FlatMapOperator;
import org.apache.flink.api.java.operators.UnsortedGrouping;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.util.Collector;

// 批处理 一篇文章
public class BatchWordCount {
    public static void main(String[] args) throws Exception {
        // 1. 创建一个执行环境
        ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();
        // 2. 从文件中读取数据
        DataSource&lt;String&gt; lineDataSource = env.readTextFile(&quot;input/words.txt&quot;);
        // 3. 将每行数据进行分词，转换成二元组类型
        FlatMapOperator&lt;String, Tuple2&lt;String, Long&gt;&gt; wordAndOneTulpe = lineDataSource.flatMap((String line, Collector&lt;Tuple2&lt;String, Long&gt;&gt; out) -&gt; {
                    // 将一行文本进行分词
                    String[] words = line.split(&quot; &quot;);
                    // 将每个单词转换成二元组输出
                    for (String word : words) {
                        out.collect(Tuple2.of(word, 1L));
                    }
                })
                .returns(Types.TUPLE(Types.STRING, Types.LONG));
        // 4. 安装word进行分组
        UnsortedGrouping&lt;Tuple2&lt;String, Long&gt;&gt; wordAndOneGroup = wordAndOneTulpe.groupBy(0);
        // 5. 分组内进行聚合统计
        AggregateOperator&lt;Tuple2&lt;String, Long&gt;&gt; sum = wordAndOneGroup.sum(1);
        // 6. 打印输出
        sum.print();
    }
}
</code></pre>
<p>DataSet API 可用 DataStream API 处理 <code>bin/flink run -Dexecution.runtime-mode=BATCH BatchWordCount.jar</code></p>
<h2 id="boundedstreamwordcountjava">BoundedStreamWordCount.java</h2>
<p>有界流单词统计</p>
<pre><code class="language-java">package com.fish.wc;

import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.DataStreamSource;
import org.apache.flink.streaming.api.datastream.KeyedStream;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.util.Collector;

public class BoundedStreamWordCount {
    public static void main(String[] args) throws Exception {
        // 1. 创建一个流式执行环境
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        // 2. 读取文件
        DataStreamSource&lt;String&gt; lineDataStreamSource = env.readTextFile(&quot;input/words.txt&quot;);
        // 3. 转换计算
        SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; wordAndOneTuple = lineDataStreamSource.flatMap((String line, Collector&lt;Tuple2&lt;String, Long&gt;&gt; out) -&gt; {
                    String[] words = line.split(&quot; &quot;);
                    for (String word : words) {
                        out.collect(Tuple2.of(word, 1L));
                    }
                })
                .returns(Types.TUPLE(Types.STRING, Types.LONG));
        // 4. 分组
        KeyedStream&lt;Tuple2&lt;String, Long&gt;, String&gt; wordAndOneKeyedStream = wordAndOneTuple.keyBy(data -&gt; data.f0);
        // 5. 求和
        SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; sum = wordAndOneKeyedStream.sum(1);
        // 6. 打印输出
        sum.print();

        // 7. 启动执行
        env.execute();
    }
}
</code></pre>
<h2 id="streamwordcountjava">StreamWordCount.java</h2>
<p>支持Socket通信</p>
<pre><code class="language-java">package com.fish.wc;

import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.api.java.utils.ParameterTool;
import org.apache.flink.streaming.api.datastream.DataStreamSource;
import org.apache.flink.streaming.api.datastream.KeyedStream;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.util.Collector;

import java.lang.reflect.Parameter;

public class StreamWordCount {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        ParameterTool parameterTool = ParameterTool.fromArgs(args);
        String hostname = parameterTool.get(&quot;host&quot;);
        int port = parameterTool.getInt(&quot;port&quot;);

        // hostname不能写IP地址，因此需要在宿主机写上主机映射
        DataStreamSource&lt;String&gt; lineDataStream = env.socketTextStream(hostname, port);
        SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; wordAndOneTuple = lineDataStream.flatMap((String line, Collector&lt;Tuple2&lt;String, Long&gt;&gt; out) -&gt; {
                    String[] words = line.split(&quot; &quot;);
                    for (String word : words) {
                        out.collect(Tuple2.of(word, 1L));
                    }
                })
                .returns(Types.TUPLE(Types.STRING, Types.LONG));
        KeyedStream&lt;Tuple2&lt;String, Long&gt;, String&gt; wordAndOneKeyedStream = wordAndOneTuple.keyBy(data -&gt; data.f0);
        SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; sum = wordAndOneKeyedStream.sum(1);
        sum.print();
        env.execute();
    }
}
</code></pre>
<h2 id="打包并提交">打包并提交</h2>
<p>先clean，再package。如果没运行过还需要compile。</p>
<p>把没有依赖的包提交到Web端上。</p>
<ul>
<li>com.fish.wc.StreamWordCount</li>
<li>Parallelism 2</li>
<li>Program Arguments
<ul>
<li>--host hadoop102 --port 7777</li>
</ul>
</li>
</ul>
<p>命令行提交</p>
<pre><code class="language-shell">./bin/flink run -m hadoop102:8081 -c com.fish.wc.StreamWordCount -p 2 --host hadoop102 --port 7777 ./FlinkTutorial-1.0-SNAPSHOT.jar
</code></pre>
<hr>
<h1 id="取消任务">取消任务</h1>
<ul>
<li>
<p>Web端点击<code>Cancel Job</code></p>
</li>
<li>
<p>命令行取消</p>
<pre><code class="language-bash">./bin/flink list -a
./bin/flink cancel jobID
</code></pre>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[HBase安装]]></title>
        <id>https://LittleFish0820.github.io/post/hbase_install/</id>
        <link href="https://LittleFish0820.github.io/post/hbase_install/">
        </link>
        <updated>2022-08-28T08:49:21.000Z</updated>
        <summary type="html"><![CDATA[<p></p>
<p>HBase 是以 hdfs 为数据存储的，一种分布式、可扩展的 NoSQL 数据库。</p>
]]></summary>
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC">
<li><a href="#zookeeper%E5%92%8Chadoop%E6%AD%A3%E5%B8%B8%E9%83%A8%E7%BD%B2">Zookeeper和Hadoop正常部署</a></li>
<li><a href="#hbase%E8%A7%A3%E5%8E%8B%E4%B8%8E%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F">HBase解压与配置环境变量</a></li>
<li><a href="#hbase%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">HBase配置文件</a>
<ul>
<li><a href="#%E4%BF%AE%E6%94%B9hbase-envsh">修改hbase-env.sh</a></li>
<li><a href="#%E4%BF%AE%E6%94%B9hbase-sitexml">修改hbase-site.xml</a></li>
<li><a href="#%E4%BF%AE%E6%94%B9regionservers">修改regionservers</a></li>
<li><a href="#%E8%A7%A3%E5%86%B3-hbase-%E5%92%8C-hadoop-%E7%9A%84-log4j-%E5%85%BC%E5%AE%B9%E6%80%A7%E9%97%AE%E9%A2%98">解决 HBase 和 Hadoop 的 log4j 兼容性问题</a></li>
</ul>
</li>
<li><a href="#%E5%88%86%E5%8F%91hbase">分发HBase</a></li>
<li><a href="#hbase%E6%9C%8D%E5%8A%A1%E5%90%AF%E5%8A%A8">HBase服务启动</a>
<ul>
<li><a href="#%E5%8D%95%E7%82%B9%E5%90%AF%E5%8A%A8">单点启动</a></li>
<li><a href="#%E7%BE%A4%E5%90%AF">群启</a></li>
<li><a href="#%E7%BE%A4%E5%81%9C">群停</a></li>
</ul>
</li>
<li><a href="#%E6%9F%A5%E7%9C%8Bhbase%E9%A1%B5%E9%9D%A2">查看HBase页面</a></li>
<li><a href="#%E9%AB%98%E5%8F%AF%E7%94%A8">高可用</a></li>
</ul>
</p>
<p>HBase 是以 hdfs 为数据存储的，一种分布式、可扩展的 NoSQL 数据库。</p>
<!-- more -->
<h1 id="zookeeper和hadoop正常部署">Zookeeper和Hadoop正常部署</h1>
<pre><code class="language-shell">zk.sh start
</code></pre>
<pre><code class="language-shell">myhadoop.sh start
</code></pre>
<hr>
<h1 id="hbase解压与配置环境变量">HBase解压与配置环境变量</h1>
<pre><code class="language-bash">cd /opt/software
tar -zxvf hbase-2.4.11-bin.tar.gz -C 
/opt/module/
</code></pre>
<pre><code>sudo vim /etc/profile.d/my_env.sh
</code></pre>
<pre><code class="language-bash">#HBASE_HOME
export HBASE_HOME=/opt/module/hbase-2.4.11
export PATH=$PATH:$HBASE_HOME/bin
</code></pre>
<pre><code class="language-bash">source /etc/profile.d/my_env.sh
</code></pre>
<pre><code class="language-bash">sudo ~/bin/xsync /etc/profile.d/my_env.sh
</code></pre>
<hr>
<h1 id="hbase配置文件">HBase配置文件</h1>
<h2 id="修改hbase-envsh">修改hbase-env.sh</h2>
<pre><code class="language-shell">export HBASE_MANAGES_ZK=false
# 不用它的zk, 用自定义的zk
</code></pre>
<h2 id="修改hbase-sitexml">修改hbase-site.xml</h2>
<p>选择部署为集群模式</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
        &lt;value&gt;hadoop102,hadoop103,hadoop104&lt;/value&gt;
        &lt;description&gt;The directory shared by RegionServers.&lt;/description&gt;
    &lt;/property&gt;

&lt;!-- &lt;property&gt;--&gt;
&lt;!-- &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;--&gt;
&lt;!-- &lt;value&gt;/export/zookeeper&lt;/value&gt;--&gt;
&lt;!-- &lt;description&gt; 记得修改 ZK 的配置文件 --&gt;
&lt;!-- ZK 的信息不能保存到临时文件夹--&gt;
&lt;!-- &lt;/description&gt;--&gt;
&lt;!-- &lt;/property&gt;--&gt;

    &lt;property&gt;
        &lt;name&gt;hbase.rootdir&lt;/name&gt;
        &lt;value&gt;hdfs://hadoop102:8020/hbase&lt;/value&gt;
        &lt;description&gt;The directory shared by RegionServers.&lt;/description&gt;
    &lt;/property&gt;
    
    &lt;property&gt;
        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<h2 id="修改regionservers">修改regionservers</h2>
<pre><code class="language-bash">hadoop102
hadoop103
hadoop104
</code></pre>
<h2 id="解决-hbase-和-hadoop-的-log4j-兼容性问题">解决 HBase 和 Hadoop 的 log4j 兼容性问题</h2>
<p>修改 HBase 的 jar 包，使用 Hadoop 的 jar 包</p>
<pre><code class="language-bash">mv /opt/module/hbase/lib/client-facing-thirdparty/slf4j-reload4j-1.7.33.jar /opt/module/hbase/lib/client-facing-thirdparty/slf4j-reload4j-1.7.33.jar.bak
</code></pre>
<hr>
<h1 id="分发hbase">分发HBase</h1>
<pre><code class="language-bash">xsync /opt/module/hbase-2.4.11/
</code></pre>
<hr>
<h1 id="hbase服务启动">HBase服务启动</h1>
<h2 id="单点启动">单点启动</h2>
<pre><code class="language-shell">bin/hbase-daemon.sh start master
bin/hbase-daemon.sh start regionserver
</code></pre>
<h2 id="群启">群启</h2>
<pre><code class="language-shell">bin/start-hbase.sh
</code></pre>
<ul>
<li>102 HMaster HRegionServer</li>
<li>103 HRegionServer</li>
<li>104 HRegionServer</li>
</ul>
<h2 id="群停">群停</h2>
<pre><code class="language-shell">bin/stop-hbase.sh
</code></pre>
<hr>
<h1 id="查看hbase页面">查看HBase页面</h1>
<p>http://hadoop102:16010</p>
<hr>
<h1 id="高可用">高可用</h1>
<ol>
<li>配置前需要关闭HBase集群</li>
</ol>
<pre><code class="language-bash">touch conf/backup-masters
echo hadoop103 &gt; conf/backup-masters
xsync conf
</code></pre>
<ol start="2">
<li>
<p>重启HBase集群，<code>jpsall</code>查看进程，并打开Web端查看。</p>
</li>
<li>
<p>当102的HMaster故障，刷新103Web端，103的Backup HMaster取而代之。</p>
</li>
</ol>
<pre><code class="language-shell">kill -9 102HMaster的端口号
</code></pre>
<ol start="4">
<li>当重启102的HMaster，103并不会退位，102成为新的Backup HMaster。</li>
</ol>
<pre><code class="language-shell">bin/hbase-daemon.sh start master
</code></pre>
<ol start="5">
<li>此时关闭集群需要在103关闭</li>
</ol>
<pre><code class="language-shell">(103) stop-hbase.sh
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Maxwell安装、配置与测试]]></title>
        <id>https://LittleFish0820.github.io/post/maxwell_install_test/</id>
        <link href="https://LittleFish0820.github.io/post/maxwell_install_test/">
        </link>
        <updated>2022-08-27T06:31:23.000Z</updated>
        <summary type="html"><![CDATA[<p>Maxwell能实时读取MySQL二进制日志binlog，生成JSON格式消息，并作为生产者发送给Kafka等应用程序。</p>
]]></summary>
        <content type="html"><![CDATA[<p>Maxwell能实时读取MySQL二进制日志binlog，生成JSON格式消息，并作为生产者发送给Kafka等应用程序。</p>
<!-- more -->
<p><ul class="markdownIt-TOC">
<li><a href="#maxwell%E5%AE%89%E8%A3%85">Maxwell安装</a></li>
<li><a href="#%E9%85%8D%E7%BD%AEmysql">配置MySQL</a>
<ul>
<li><a href="#%E5%90%AF%E7%94%A8mysql-binlog">启用MySQL Binlog</a></li>
<li><a href="#%E5%88%9B%E5%BB%BAmaxwell%E6%89%80%E9%9C%80%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E7%94%A8%E6%88%B7">创建Maxwell所需数据库和用户</a></li>
<li><a href="#%E9%85%8D%E7%BD%AEmaxwell">配置Maxwell</a></li>
</ul>
</li>
<li><a href="#maxwell%E4%BD%BF%E7%94%A8">Maxwell使用</a>
<ul>
<li><a href="#%E5%90%AF%E5%8A%A8kafka">启动Kafka</a></li>
<li><a href="#maxwell%E5%90%AF%E5%8A%A8%E5%92%8C%E5%81%9C%E6%AD%A2">Maxwell启动和停止</a></li>
<li><a href="#%E6%B5%8B%E8%AF%95">测试</a>
<ul>
<li><a href="#%E5%9C%A8103%E5%90%AF%E5%8A%A8kafka%E6%B6%88%E8%B4%B9">在103启动kafka消费</a></li>
<li><a href="#%E5%9C%A8102%E7%94%9F%E6%88%90%E6%A8%A1%E6%8B%9F%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE">在102生成模拟业务数据</a></li>
</ul>
</li>
<li><a href="#maxwell-bootstrap%E5%8E%86%E5%8F%B2%E6%95%B0%E6%8D%AE%E5%85%A8%E9%87%8F%E5%90%8C%E6%AD%A5">Maxwell-bootstrap历史数据全量同步</a></li>
</ul>
</li>
<li><a href="#%E9%87%87%E9%9B%86%E9%80%9A%E9%81%93maxwell%E9%85%8D%E7%BD%AE">采集通道Maxwell配置</a></li>
</ul>
</p>
<h1 id="maxwell安装">Maxwell安装</h1>
<pre><code class="language-shell">tar -zxvf maxwell-1.29.2.tar.gz -C /opt/module
</code></pre>
<h1 id="配置mysql">配置MySQL</h1>
<h2 id="启用mysql-binlog">启用MySQL Binlog</h2>
<pre><code class="language-shell">sudo vim /etc/my.cnf

# 数据库id
server-id=1
# 启动binlog
log-bin=mysql-bin
# binlog类型，maxwell要求为row类型
binlog_format=row
# 启用binlog的数据库，需根据实际情况作出修改
binlog-do-db=gmall
#binlog-ignore-db=gmall 100个数据库忽略1个
</code></pre>
<p>重启MySQL，测试是否生效</p>
<pre><code class="language-shell">sudo systemctl restart mysqld
mysql -uroot -p123456
</code></pre>
<pre><code class="language-sql">show master status;
</code></pre>
<h2 id="创建maxwell所需数据库和用户">创建Maxwell所需数据库和用户</h2>
<ol>
<li>创建数据库</li>
</ol>
<pre><code class="language-sql">create database maxwell;
</code></pre>
<ol start="2">
<li>降低密码级别 (Alt快捷复制)</li>
</ol>
<pre><code class="language-sql">set global validate_password_policy=0;
set global validate_password_length=4; # &gt;=4
</code></pre>
<ol start="3">
<li>创建Maxwell用户并赋予其必要权限</li>
</ol>
<pre><code class="language-sql">create user 'maxwell'@'%' identified by 'maxwell';
grant all on maxwell.* to 'maxwell'@'%';
grant select, replication client, replication slave on *.* to 'maxwell'@'%';

quit;
</code></pre>
<h2 id="配置maxwell">配置Maxwell</h2>
<pre><code class="language-shell">cd /opt/module/maxwell
cp config.properties.example config.properties
vim config.properties
</code></pre>
<pre><code class="language-shell"># Maxwell数据发送目的地
producer=kafka

# 目标Kafka集群地址
kafka.bootstrap.servers=hadoop102:9092,hadoop103:9092

# 目标Kafka topic
# 静态配置
kafka_topic=maxwell

# MySQL 相关配置
host=hadoop102
user=maxwell
password=maxwell
jdbc_options=useSLL=false&amp;serverTimezone=Asia/Shanghai
</code></pre>
<h1 id="maxwell使用">Maxwell使用</h1>
<h2 id="启动kafka">启动Kafka</h2>
<p>先启动Zookeeper</p>
<pre><code class="language-bash">zk.sh
kf.sh
</code></pre>
<h2 id="maxwell启动和停止">Maxwell启动和停止</h2>
<pre><code class="language-shell">./bin/maxwell --config ./config.properties --daemon
</code></pre>
<p>停止没有专用命令，须使用<code>kill -9</code>，移步shell脚本大全</p>
<p>出错查信息到<code>./log</code></p>
<h2 id="测试">测试</h2>
<h3 id="在103启动kafka消费">在103启动kafka消费</h3>
<pre><code class="language-shell">kafka-console-consume.sh --bootstrap-server hadoop102:9092 --topic maxwell
</code></pre>
<h3 id="在102生成模拟业务数据">在102生成模拟业务数据</h3>
<p>需要保证配置的账号密码一致</p>
<pre><code class="language-shell">java -jar gmall2020-mock-db-2021-11-14.jar
</code></pre>
<h2 id="maxwell-bootstrap历史数据全量同步">Maxwell-bootstrap历史数据全量同步</h2>
<pre><code class="language-shell">(102) /opt/module/maxwell/bin/maxwell-bootstrap --database gmall --table user_info --config /opt/module/maxwell/config.properties
</code></pre>
<h1 id="采集通道maxwell配置">采集通道Maxwell配置</h1>
<p>把 topic 从 maxwell 改成 topic_db 即可</p>
<pre><code class="language-shell">cd /opt/module/maxwell
vim config.properties
</code></pre>
<p>改完配置后需要重启</p>
<pre><code class="language-shell">mxw.sh restart
</code></pre>
<p>103启动kafka</p>
<pre><code class="language-shell">kafka-console-consume.sh --bootstrap-server hadoop102:9092 --topic topic_db
</code></pre>
<p>102写数据</p>
<pre><code class="language-shell">java -jar gmall2020-mock-db-2021-11-14.jar
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MySQL安装 (Linux)]]></title>
        <id>https://LittleFish0820.github.io/post/mysql_install/</id>
        <link href="https://LittleFish0820.github.io/post/mysql_install/">
        </link>
        <updated>2022-08-25T21:54:55.000Z</updated>
        <summary type="html"><![CDATA[<p></p>
<p>Linux环境下安装MySQL。</p>
]]></summary>
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC">
<li><a href="#%E5%AE%89%E8%A3%85%E5%8C%85%E5%87%86%E5%A4%87">安装包准备</a>
<ul>
<li><a href="#%E8%8B%A5%E8%87%AA%E5%B8%A6mysql-libs%E5%8D%B8%E8%BD%BD">若自带Mysql-libs，卸载</a></li>
<li><a href="#%E8%8B%A5%E6%98%AF%E6%9C%80%E5%B0%8F%E5%AE%89%E8%A3%85">若是最小安装</a></li>
</ul>
</li>
<li><a href="#%E5%AE%89%E8%A3%85mysql">安装MySQL</a>
<ul>
<li><a href="#%E5%90%AF%E5%8A%A8mysql">启动MySQL</a></li>
<li><a href="#%E6%9F%A5%E7%9C%8Bmysql%E5%AF%86%E7%A0%81">查看MySQL密码</a></li>
</ul>
</li>
<li><a href="#%E9%85%8D%E7%BD%AEmysql">配置MySQL</a></li>
<li><a href="#%E4%BD%BF%E7%94%A8sqlyog">使用SQLyog</a></li>
<li><a href="#%E8%BF%9E%E6%8E%A5sqlyog%E6%8A%A5%E9%94%99windows%E4%B8%8B">连接SQLyog报错（Windows下）</a>
<ul>
<li><a href="#%E9%94%99%E8%AF%AF%E7%A0%811045">错误码1045</a></li>
</ul>
</li>
</ul>
</p>
<p>Linux环境下安装MySQL。</p>
<!-- more -->
<h1 id="安装包准备">安装包准备</h1>
<pre><code class="language-bash">01_mysql-community-common-5.7.16-1.el7.x86_64.rpm 

02_mysql-community-libs-5.7.16-1.el7.x86_64.rpm 

03_mysql-community-libs-compat-5.7.16-1.el7.x86_64.rpm 

04_mysql-community-client-5.7.16-1.el7.x86_64.rpm 

05_mysql-community-server-5.7.16-1.el7.x86_64.rpm 

mysql-connector-java-5.1.27-bin.jar
</code></pre>
<h2 id="若自带mysql-libs卸载">若自带Mysql-libs，卸载</h2>
<pre><code class="language-shell">rpm -qa | grep -i -E mysql\|mariadb | xargs -n1 sudo rpm -e --nodeps
</code></pre>
<h2 id="若是最小安装">若是最小安装</h2>
<pre><code class="language-shell">sudo yum remove mysql-libs
sudo yum install libaio
sudo yum -y install autoconf
</code></pre>
<hr>
<h1 id="安装mysql">安装MySQL</h1>
<pre><code class="language-shell">sudo rpm -ivh 01_mysql-community-common-5.7.16-1.el7.x86_64.rpm

sudo rpm -ivh 02_mysql-community-libs-5.7.16-1.el7.x86_64.rpm

sudo rpm -ivh 03_mysql-community-libs-compat-5.7.16-1.el7.x86_64.rpm

sudo rpm -ivh 04_mysql-community-client-5.7.16-1.el7.x86_64.rpm

sudo rpm -ivh 05_mysql-community-server-5.7.16-1.el7.x86_64.rpm
</code></pre>
<h2 id="启动mysql">启动MySQL</h2>
<pre><code class="language-shell">sudo systemctl start mysqld
sudo systemctl status mysqld
</code></pre>
<h2 id="查看mysql密码">查看MySQL密码</h2>
<pre><code class="language-shell">sudo cat /var/log/mysqld.log | grep password
</code></pre>
<h1 id="配置mysql">配置MySQL</h1>
<ol>
<li>用初始密码进入MySQL</li>
</ol>
<pre><code class="language-bash">mysql -uroot -p'password'
</code></pre>
<ol start="2">
<li>更改密码策略</li>
</ol>
<pre><code class="language-sql">set global validate_password_length=4;
set global validate_password_policy=0;
</code></pre>
<ol start="3">
<li>设置简单密码</li>
</ol>
<pre><code class="language-sql">set password=password(&quot;123456&quot;);
</code></pre>
<ol start="4">
<li>进入MySQL库</li>
</ol>
<pre><code class="language-bash">use mysql
</code></pre>
<ol start="5">
<li>查询user表，并把Host表内容修改为%</li>
</ol>
<pre><code class="language-sql">select user host from user;
update user set host='%' where user = &quot;root&quot;;
</code></pre>
<ol start="6">
<li>刷新并退出</li>
</ol>
<pre><code class="language-sql">flush privileges;
quit;
</code></pre>
<h1 id="使用sqlyog">使用SQLyog</h1>
<p>新建连接gmall<br>
新建数据库gmall<br>
导入脚本文件生成数据</p>
<hr>
<h1 id="连接sqlyog报错windows下">连接SQLyog报错（Windows下）</h1>
<h2 id="错误码1045">错误码1045</h2>
<ol>
<li>
<p>管理员 net stop mysql</p>
</li>
<li>
<p>在mysql-init.txt文件夹写下</p>
<pre><code class="language-sql">set password for 'root@localhost'=password('123456');
</code></pre>
</li>
<li>
<p>来到mysql安装bin目录下执行</p>
<pre><code class="language-shell">mysqld -nt --init-file=../mysql-init.txt
</code></pre>
</li>
<li>
<p>管理员 net start mysql</p>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flume实现日志采集]]></title>
        <id>https://LittleFish0820.github.io/post/flume_log_gather/</id>
        <link href="https://LittleFish0820.github.io/post/flume_log_gather/">
        </link>
        <updated>2022-08-25T08:22:01.000Z</updated>
        <summary type="html"><![CDATA[<p></p>
<p>日志采集Flume的模型、配置、测试、启停脚本</p>
]]></summary>
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC">
<li><a href="#%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86%E6%A6%82%E8%BF%B0">日志采集概述</a></li>
<li><a href="#%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86flume%E9%85%8D%E7%BD%AE">日志采集Flume配置</a>
<ul>
<li><a href="#%E5%88%9B%E5%BB%BAflume%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">创建Flume配置文件</a></li>
<li><a href="#%E7%BC%96%E5%86%99flume%E6%8B%A6%E6%88%AA%E5%99%A8">编写Flume拦截器</a></li>
</ul>
</li>
<li><a href="#%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86flume%E6%B5%8B%E8%AF%95">日志采集Flume测试</a>
<ul>
<li><a href="#%E5%90%AF%E5%8A%A8zookeeper-kafka%E9%9B%86%E7%BE%A4">启动Zookeeper、Kafka集群</a></li>
<li><a href="#%E5%90%AF%E5%8A%A8102%E7%9A%84%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86flume">启动102的日志采集Flume</a></li>
<li><a href="#%E5%90%AF%E5%8A%A8%E4%B8%80%E4%B8%AAkafka%E7%9A%84console-consumer">启动一个Kafka的Console-Consumer</a></li>
<li><a href="#%E7%94%9F%E6%88%90%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE">生成模拟数据</a></li>
</ul>
</li>
<li><a href="#%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86flume%E5%90%AF%E5%81%9C%E8%84%9A%E6%9C%AC">日志采集Flume启停脚本</a>
<ul>
<li><a href="#%E5%88%86%E5%8F%91%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86flume%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%92%8C%E6%8B%A6%E6%88%AA%E5%99%A8">分发日志采集Flume配置文件和拦截器</a></li>
<li><a href="#%E7%BC%96%E5%86%99%E8%84%9A%E6%9C%AC">编写脚本</a></li>
</ul>
</li>
<li><a href="#%E5%BC%82%E5%B8%B8%E6%83%85%E5%86%B5">异常情况</a></li>
</ul>
</p>
<p>日志采集Flume的模型、配置、测试、启停脚本</p>
<!-- more -->
<h1 id="日志采集概述">日志采集概述</h1>
<p>按照规划，需要采集的用户行为日志文件分布在102，103 两台日志服务器，故需要在102，103 两台节点配置日志采集 Flume。</p>
<p>日志采集 Flume 需要采集日志文件内容，并对日志格式(json)进行校验，然后将校验通过的日志发送到 Kafka。</p>
<ul>
<li>TaildirSource 支持断点续传，多目录</li>
<li>KafkaChannel 省去Sink，提高了效率</li>
<li>配置日志校验拦截器</li>
</ul>
<h1 id="日志采集flume配置">日志采集Flume配置</h1>
<h2 id="创建flume配置文件">创建Flume配置文件</h2>
<pre><code class="language-shell">vim /opt/mudule/flume/job/file_to_kafka.conf
</code></pre>
<pre><code>#定义组件 
a1.sources = r1 
a1.channels = c1 

#配置 source 
a1.sources.r1.type = TAILDIR 
a1.sources.r1.filegroups = f1 
a1.sources.r1.filegroups.f1 = /opt/module/applog/log/app.* 
a1.sources.r1.positionFile = /opt/module/flume-1.9.0/taildir_position.json 
a1.sources.r1.interceptors = i1 
a1.sources.r1.interceptors.i1.type = com.fish.gmall.flume.interceptor.ETLInterceptor$Builder 

#配置 channel
a1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.c1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092 
a1.channels.c1.kafka.topic = topic_log 
a1.channels.c1.parseAsFlumeEvent = false 

#组装 
a1.sources.r1.channels = c1
</code></pre>
<hr>
<h2 id="编写flume拦截器">编写Flume拦截器</h2>
<ol>
<li>
<p>创建 Maven 工程 flume-interceptor</p>
</li>
<li>
<p>创建包 com.fish.gmall.flume.interceptor</p>
</li>
<li>
<p>在 pom.xml 文件中添加如下配置</p>
<pre><code class="language-xml">&lt;dependencies&gt; 
    &lt;dependency&gt; 
        &lt;groupId&gt;org.apache.flume&lt;/groupId&gt; 
        &lt;artifactId&gt;flume-ng-core&lt;/artifactId&gt; 
        &lt;version&gt;1.9.0&lt;/version&gt; 
        &lt;scope&gt;provided&lt;/scope&gt; 
    &lt;/dependency&gt; 
    &lt;dependency&gt; 
        &lt;groupId&gt;com.alibaba&lt;/groupId&gt; 
        &lt;artifactId&gt;fastjson&lt;/artifactId&gt; 
        &lt;version&gt;1.2.62&lt;/version&gt; 
    &lt;/dependency&gt; 
&lt;/dependencies&gt; 

&lt;build&gt; 
    &lt;plugins&gt; 
        &lt;plugin&gt; 
            &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; 
            &lt;version&gt;2.3.2&lt;/version&gt; 
            &lt;configuration&gt; 
                &lt;source&gt;1.8&lt;/source&gt; 
                &lt;target&gt;1.8&lt;/target&gt; 
            &lt;/configuration&gt; 
        &lt;/plugin&gt; 
        &lt;plugin&gt; 
            &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; 
            &lt;configuration&gt;
                &lt;descriptorRefs&gt; 
                    &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; 
                &lt;/descriptorRefs&gt;
            &lt;/configuration&gt;
            &lt;executions&gt;
                &lt;execution&gt; 
                    &lt;id&gt;make-assembly&lt;/id&gt; 
                    &lt;phase&gt;package&lt;/phase&gt; 
                    &lt;goals&gt; 
                        &lt;goal&gt;single&lt;/goal&gt; 
                    &lt;/goals&gt;
                &lt;/execution&gt;
            &lt;/executions&gt;
        &lt;/plugin&gt;
    &lt;/plugins&gt; 
&lt;/build&gt;
</code></pre>
</li>
<li>
<p>在 com.fish.gmall.flume.utils 包下创建 JSONUtil 类</p>
<pre><code class="language-java">package com.fish.gmall.flume.utils;

import com.alibaba.fastjson.JSONException;
import com.alibaba.fastjson.JSONObject;

public class JSONUtil {

    // 校验JSON是不是一个合法的JSON
    public static boolean isJSONValidate(String log) {
        // 通过异常捕捉校验JSON是否合法
        try {
            JSONObject.parseObject(log);
            return true;
        } catch (JSONException e) {
            return false;
        }
    }

//    public static void main(String[] args) {
//        // 不合法报错
//        // System.out.println(isJSONValidate(&quot;{id:}&quot;));
//    }
}

</code></pre>
</li>
<li>
<p>在 com.atguigu.gmall.flume.interceptor 包下创建 ETLInterceptor 类</p>
<pre><code class="language-java">package com.fish.gmall.flume.interceptor;

import com.fish.gmall.flume.utils.JSONUtil;
import org.apache.flume.Context;
import org.apache.flume.Event;
import org.apache.flume.interceptor.Interceptor;

import java.nio.charset.StandardCharsets;
import java.util.Iterator;
import java.util.List;

public class ETLInterceptor implements Interceptor {

    @Override
    public void initialize() {

    }

    @Override
    public Event intercept(Event event) {
        // 1 获取body当中的数据
        byte[] body = event.getBody();
        String log = new String(body, StandardCharsets.UTF_8);

        // 2 判断是不是合法的Json
        if (JSONUtil.isJSONValidate(log)) {
            return event;
        }

        // 3 是: return event; 不是: return null;
        return null;
    }

    @Override
    public List&lt;Event&gt; intercept(List&lt;Event&gt; list) {
//        for (int i = 0; i &lt; list.size(); i++) {
//            Event event = list.get(i);
//            if (intercept(event) == null) {
//                list.remove(i);  // 删除的时候list尺寸变小，再删可能报错
//            }
//        }
        Iterator&lt;Event&gt; iterator = list.iterator();
        while (iterator.hasNext()) {   // 是否有当前这个元素
            Event event = iterator.next(); // 把数据拿出来并且指针向后移
            if (intercept(event) == null) {
                iterator.remove();
            }
        }
        return list;
    }

    @Override
    public void close() {

    }

    public static class Builder implements Interceptor.Builder {

        @Override
        public Interceptor build() {
            return null;
        }

        @Override
        public void configure(Context context) {

        }
    }
}

</code></pre>
</li>
<li>
<p>IDEA右侧Maven栏，先clean再package</p>
</li>
<li>
<p>将有依赖的包放入102的/opt/module/flume/lib文件夹下</p>
</li>
</ol>
<hr>
<h1 id="日志采集flume测试">日志采集Flume测试</h1>
<h2 id="启动zookeeper-kafka集群">启动Zookeeper、Kafka集群</h2>
<p>请移步Zookeeper、Kafka集群启停脚本</p>
<h2 id="启动102的日志采集flume">启动102的日志采集Flume</h2>
<pre><code class="language-shell">bin/flume-ng agent -n a1 -c conf/ -f job/file_to_kafka.conf -Dflume.root.logger=info,console
</code></pre>
<h2 id="启动一个kafka的console-consumer">启动一个Kafka的Console-Consumer</h2>
<pre><code class="language-shell"># 还是102
bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic topic_log
</code></pre>
<h2 id="生成模拟数据">生成模拟数据</h2>
<pre><code class="language-shell">lg.sh  # 移步脚本
</code></pre>
<p>观察Kafka消费者是否能消费到数据</p>
<hr>
<h1 id="日志采集flume启停脚本">日志采集Flume启停脚本</h1>
<h2 id="分发日志采集flume配置文件和拦截器">分发日志采集Flume配置文件和拦截器</h2>
<p>将 102 的配置文件和拦截器 jar 包向 103 发送一份</p>
<pre><code class="language-bash">$ scp -r job hadoop103:/opt/module/flume/
$ scp lib/flume-interceptor-1.0-SNAPSHOT-jar-with-dependencies.jar hadoop103:/opt/module/flume/lib/
</code></pre>
<h2 id="编写脚本">编写脚本</h2>
<p>移步脚本大全</p>
<h1 id="异常情况">异常情况</h1>
<ol>
<li>-daemon 写成 --daemon 导致kafka无法启动，但是却很久才发现，最后通过看异常信息发现。</li>
<li>自定义拦截器写错一行 build 返回值应该是一个拦截器 但是我写成null 导致flume启动报异常。也是过了很久通过看异常信息才发现。</li>
</ol>
<p>总结：这些错误比较小儿科，因此上百度搜不到答案，需要自己看异常信息解决问题。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hadoop集群搭建]]></title>
        <id>https://LittleFish0820.github.io/post/hadoop_cluster/</id>
        <link href="https://LittleFish0820.github.io/post/hadoop_cluster/">
        </link>
        <updated>2022-08-24T15:23:23.000Z</updated>
        <summary type="html"><![CDATA[<p></p>
<p>Hadoop集群搭建详细过程，待完善</p>
]]></summary>
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC">
<li><a href="#%E5%87%86%E5%A4%87%E4%B8%89%E5%8F%B0%E8%99%9A%E6%8B%9F%E6%9C%BA">准备三台虚拟机</a>
<ul>
<li><a href="#%E5%AE%89%E8%A3%85%E4%B8%80%E5%8F%B0centos-7%E8%99%9A%E6%8B%9F%E6%9C%BA">安装一台CentOS 7虚拟机</a></li>
<li><a href="#%E5%8D%95%E5%8F%B0%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE">单台虚拟机环境配置</a></li>
</ul>
</li>
<li><a href="#%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95">免密登录</a></li>
<li><a href="#%E5%AE%89%E8%A3%85jdk102">安装JDK（102）</a></li>
<li><a href="#%E5%AE%89%E8%A3%85hadoop102">安装Hadoop（102）</a></li>
<li><a href="#%E7%BC%96%E5%86%99%E9%9B%86%E7%BE%A4%E5%88%86%E5%8F%91%E8%84%9A%E6%9C%AC">编写集群分发脚本</a></li>
<li><a href="#%E5%88%86%E5%8F%91jdkhadoop%E5%8F%8A%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F">分发JDK，Hadoop及环境变量</a></li>
<li><a href="#hadoop%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">Hadoop配置文件</a>
<ul>
<li><a href="#core-sitexml">core-site.xml</a></li>
<li><a href="#hdfs-sitexml">hdfs-site.xml</a></li>
<li><a href="#yarn-sitexml">yarn-site.xml</a></li>
<li><a href="#mapred-sitexml">mapred-site.xml</a></li>
<li><a href="#%E5%88%86%E5%8F%91%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">分发配置文件</a></li>
</ul>
</li>
<li><a href="#%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4">启动集群</a>
<ul>
<li><a href="#%E9%85%8D%E7%BD%AEworkers">配置workers</a></li>
<li><a href="#%E6%A0%BC%E5%BC%8F%E5%8C%96namenode%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%90%AF%E5%8A%A8">格式化NameNode(第一次启动)</a></li>
<li><a href="#%E5%90%AF%E5%8A%A8%E5%8E%86%E5%8F%B2%E6%9C%8D%E5%8A%A1%E5%99%A8-102">启动历史服务器 (102)</a></li>
<li><a href="#web%E7%AB%AF">Web端</a>
<ul>
<li><a href="#2nn-bug%E4%BF%AE%E6%94%B9">2nn bug修改</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</p>
<p>Hadoop集群搭建详细过程，待完善</p>
<!-- more -->
<h1 id="准备三台虚拟机">准备三台虚拟机</h1>
<h2 id="安装一台centos-7虚拟机">安装一台CentOS 7虚拟机</h2>
<ol>
<li>安装VMware，准备CentOS 7镜像文件</li>
<li>新建虚拟机，内存8G，磁盘64G</li>
<li>启动虚拟机，选择最小安装</li>
<li>等待安装完成，重启虚拟机</li>
</ol>
<h2 id="单台虚拟机环境配置">单台虚拟机环境配置</h2>
<p><strong>1. 安装net-tools，vim</strong></p>
<pre><code class="language-shell">yum install -y epel-release
yum install -y net-tools vim
</code></pre>
<p><strong>2. 关闭防火墙</strong></p>
<pre><code class="language-shell">systemctl stop firewalld
systemctl disable firewalld.service
systemctl status firewalld
</code></pre>
<p><strong>3. 创建普通用户</strong></p>
<pre><code class="language-shell">useradd fish
passwd fish
</code></pre>
<p>添加权限</p>
<pre><code class="language-SHELL">vim /etc/sudoers
## Allow root to run any commands anywhere 
root ALL=(ALL) ALL 
fish ALL=(ALL) NOPASSWD:ALL    # 在root下面添加
</code></pre>
<p><strong>4. 创建项目文件夹，修改文件夹的所有者id</strong></p>
<pre><code class="language-shell">chown lxx:lxx /opt/module /opt/software
</code></pre>
<p><strong>5. 卸载自带Java(最小安装略过这一步)</strong></p>
<pre><code class="language-shell">rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps
</code></pre>
<p><strong>6. 修改虚拟机的静态IP</strong></p>
<pre><code class="language-shell">vim /etc/sysconfig/network-scripts/ifcfg-ens33

BOOTPROTO=static 
IPADDR=192.168.1.101 
GATEWAY=192.168.1.2 
DNS1=192.168.1.2
</code></pre>
<p>Windows也要修改。</p>
<p><strong>7. 修改主机名和配置主机名映射</strong></p>
<pre><code class="language-shell">vim /etc/hosts
192.168.1.100 hadoop100 
192.168.1.101 hadoop101 
192.168.1.102 hadoop102
192.168.1.103 hadoop103 
192.168.1.104 hadoop104

vim /etc/hostname
hadoop102
</code></pre>
<p>Windows的hosts也要修改</p>
<pre><code class="language-bash">C:\Windows\System32\drivers\etc
</code></pre>
<p><strong>8. 虚拟机重启，克隆两台虚拟机</strong></p>
<p>只需要修改主机名和静态IP地址，重启</p>
<p><strong>9. 准备Xshell和Xftp</strong></p>
<h1 id="免密登录">免密登录</h1>
<pre><code class="language-shell">ssh-keygen -t rsa
ssh-copy-id hadoop102
ssh-copy-id hadoop103
ssh-copy-id hadoop104
</code></pre>
<p>每台分发3次，三台共分发9次</p>
<h1 id="安装jdk102">安装JDK（102）</h1>
<p>解压后配置环境变量</p>
<pre><code class="language-shell">vim /etc/profile.d/my_env.sh

#JAVA_HOME 
export JAVA_HOME=/opt/module/jdk1.8.0_212 
export PATH=$PATH:$JAVA_HOME/bin

source /etc/profile
</code></pre>
<p>测试JDK是否安装成功</p>
<pre><code class="language-shell">java -version
</code></pre>
<h1 id="安装hadoop102">安装Hadoop（102）</h1>
<p>解压后配置环境变量</p>
<pre><code class="language-shell">vim /etc/profile.d/my_env.sh

# HADOOP_HOME 
export HADOOP_HOME=/opt/module/hadoop-3.1.3 
export PATH=$PATH:$HADOOP_HOME/bin 
export PATH=$PATH:$HADOOP_HOME/sbin

source /etc/profile
</code></pre>
<p>测试是否安装成功</p>
<pre><code class="language-shell">hadoop version
</code></pre>
<h1 id="编写集群分发脚本">编写集群分发脚本</h1>
<p>请查看Shell标签下的hadoop脚本文章。</p>
<h1 id="分发jdkhadoop及环境变量">分发JDK，Hadoop及环境变量</h1>
<pre><code class="language-shell">xsync /opt/module/
xsync /etc/profile.d/my_env.sh
</code></pre>
<h1 id="hadoop配置文件">Hadoop配置文件</h1>
<h2 id="core-sitexml">core-site.xml</h2>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
&lt;configuration&gt;
    &lt;!-- 指定 NameNode 的地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://hadoop102:8020&lt;/value&gt;     &lt;!-- 改！--&gt;
    &lt;/property&gt;
    &lt;!-- 指定 hadoop 数据的存储目录 --&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;/opt/module/hadoop-3.1.3/data&lt;/value&gt;
    &lt;/property&gt;
    
    &lt;!-- 配置 HDFS 网页登录使用的静态用户为 atguigu --&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;
        &lt;value&gt;fish&lt;/value&gt;					 					&lt;!-- 改！--&gt;
    &lt;/property&gt;
    
    &lt;!-- 配置该atguigu(superUser)允许通过代理访问的主机节点 --&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.proxyuser.fish.hosts&lt;/name&gt;				&lt;!-- 改！--&gt;
        &lt;value&gt;*&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 配置该atguigu(superUser)允许通过代理用户所属组 --&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.proxyuser.fish.groups&lt;/name&gt;            &lt;!-- 改！--&gt;
        &lt;value&gt;*&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 配置该atguigu(superUser)允许通过代理的用户--&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.proxyuser.fish.users&lt;/name&gt;             &lt;!-- 改！--&gt;
        &lt;value&gt;*&lt;/value&gt;
	&lt;/property&gt;   
    
&lt;/configuration&gt;
</code></pre>
<h2 id="hdfs-sitexml">hdfs-site.xml</h2>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
&lt;configuration&gt;
    &lt;!-- nn web 端访问地址--&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;
        &lt;value&gt;hadoop102:9870&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 2nn web 端访问地址--&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
        &lt;value&gt;hadoop104:9868&lt;/value&gt;
    &lt;/property&gt;
    
    &lt;!-- 测试环境指定HDFS副本的数量1 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;3&lt;/value&gt;
    &lt;/property&gt;
    
&lt;/configuration&gt;
</code></pre>
<h2 id="yarn-sitexml">yarn-site.xml</h2>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;

&lt;configuration&gt;
    &lt;!-- 指定 MR 走 shuffle --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定 ResourceManager 的地址--&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
        &lt;value&gt;hadoop103&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 环境变量的继承 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;
     	&lt;value&gt;
JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME
        &lt;/value&gt;
    &lt;/property&gt;
    
    &lt;!--yarn单个容器允许分配的最大最小内存 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;
        &lt;value&gt;512&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;
        &lt;value&gt;4096&lt;/value&gt;
    &lt;/property&gt;
    
    &lt;!-- yarn容器允许管理的物理内存大小 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
        &lt;value&gt;4096&lt;/value&gt;
    &lt;/property&gt;
    
    &lt;!-- 关闭yarn对物理内存和虚拟内存的限制检查 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
    
    &lt;!-- 开启日志聚集功能 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 设置日志聚集服务器地址 --&gt;
    &lt;property&gt; 
        &lt;name&gt;yarn.log.server.url&lt;/name&gt; 
        &lt;value&gt;http://hadoop102:19888/jobhistory/logs&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 设置日志保留时间为 7 天 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;
        &lt;value&gt;604800&lt;/value&gt;
    &lt;/property&gt;
    
&lt;/configuration&gt;
</code></pre>
<h2 id="mapred-sitexml">mapred-site.xml</h2>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
&lt;configuration&gt;
    &lt;!-- 指定 MapReduce 程序运行在 Yarn 上 --&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
    
    &lt;!-- 历史服务器端地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
        &lt;value&gt;hadoop102:10020&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 历史服务器 web 端地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
        &lt;value&gt;hadoop102:19888&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<h2 id="分发配置文件">分发配置文件</h2>
<pre><code class="language-shell">xsync /opt/module/hadoop-3.1.3/etc/hadoop/
</code></pre>
<h1 id="启动集群">启动集群</h1>
<h2 id="配置workers">配置workers</h2>
<pre><code class="language-shell">vim /opt/module/hadoop-3.1.3/etc/hadoop/workers
hadoop102
hadoop103
hadoop104

xsync /opt/module/hadoop-3.1.3/etc
</code></pre>
<h2 id="格式化namenode第一次启动">格式化NameNode(第一次启动)</h2>
<pre><code class="language-shell">hdfs namenode -format  (102)
sbin/start-dfs.sh      (102)
sbin/start-yarn.sh     (103)
</code></pre>
<h2 id="启动历史服务器-102">启动历史服务器 (102)</h2>
<pre><code class="language-shell">mapred --daemon start historyserver
jps
</code></pre>
<h2 id="web端">Web端</h2>
<p>NameNode  http://hadoop102:9870</p>
<p>http://hadoop103:8088</p>
<p>http://hadoop102:19888/jobhistory</p>
<p>2nn http://hadoop104:9868</p>
<h3 id="2nn-bug修改">2nn bug修改</h3>
<p>查看浏览器控制台，追根溯源</p>
<pre><code class="language-shell"># hadoop104
$ cd /opt/module/hadoop-3.1.3/share/hadoop/hdfs/webapps/static
$ vim dfs-dust.js
# 改成 return Number(v).toLocaleString();
</code></pre>
<p>清除浏览器缓存，刷新即可。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Git与代码托管中心]]></title>
        <id>https://LittleFish0820.github.io/post/git4github/</id>
        <link href="https://LittleFish0820.github.io/post/git4github/">
        </link>
        <updated>2022-08-23T15:23:23.000Z</updated>
        <summary type="html"><![CDATA[<p></p>
<p>IDEA、Pycharm集成git，GitHub。</p>
]]></summary>
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC">
<li><a href="#git-%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E6%9C%BA%E5%88%B6">Git 团队协作机制</a></li>
<li><a href="#github-%E6%93%8D%E4%BD%9C">GitHub 操作</a>
<ul>
<li><a href="#%E5%88%9B%E5%BB%BA%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93">创建远程仓库</a></li>
<li><a href="#%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93%E6%93%8D%E4%BD%9C">远程仓库操作</a></li>
<li><a href="#%E9%82%80%E8%AF%B7%E5%90%88%E4%BD%9C%E4%BC%99%E4%BC%B4">邀请合作伙伴</a></li>
<li><a href="#%E8%B7%A8%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C">跨团队协作</a></li>
<li><a href="#%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95">免密登录</a></li>
</ul>
</li>
<li><a href="#idea-%E9%9B%86%E6%88%90-git">IDEA 集成 Git</a>
<ul>
<li><a href="#ignore%E5%BF%BD%E7%95%A5%E8%A7%84%E5%88%99%E6%96%87%E4%BB%B6">.ignore忽略规则文件</a></li>
<li><a href="#%E5%AE%9A%E4%BD%8Dgit%E7%A8%8B%E5%BA%8F">定位Git程序</a></li>
</ul>
</li>
<li><a href="#idea-%E9%9B%86%E6%88%90-github">IDEA 集成 GitHub</a></li>
<li><a href="#%E7%A0%81%E4%BA%91">码云</a></li>
<li><a href="#gitlab">GitLab</a></li>
</ul>
</p>
<p>IDEA、Pycharm集成git，GitHub。</p>
<!--more-->
<h1 id="git-团队协作机制">Git 团队协作机制</h1>
<h1 id="github-操作">GitHub 操作</h1>
<h2 id="创建远程仓库">创建远程仓库</h2>
<figure data-type="image" tabindex="1"><img src="https://LittleFish0820.github.io/post-images/1661196767433.png" alt="" loading="lazy"></figure>
<p>下滑点击<code>Create repository</code>即可</p>
<p>快速开始：仓库名，还有一些操作命令</p>
<figure data-type="image" tabindex="2"><img src="https://LittleFish0820.github.io/post-images/1661196819092.png" alt="" loading="lazy"></figure>
<h2 id="远程仓库操作">远程仓库操作</h2>
<p><strong>1. 查看远程仓库别名</strong></p>
<pre><code class="language-shell">$ git remote -v
</code></pre>
<p><strong>2. 创建远程仓库别名</strong></p>
<pre><code class="language-shell">$ git remote add pySpider https://github.com/LittleFish0820/python-spider.git

$ git remote -v
pySpider        https://github.com/LittleFish0820/python-spider.git (fetch)
pySpider        https://github.com/LittleFish0820/python-spider.git (push)
</code></pre>
<p>可拉可推</p>
<p><strong>3. 删除远程仓库别名</strong></p>
<pre><code class="language-shell">$ git remote remove pySpider
$ git remote -v
</code></pre>
<p><strong>4. 推送本地分支到远程仓库</strong></p>
<pre><code class="language-shell">$ git push pySpider master
</code></pre>
<p>需要登录。换一种，先移步免密登录</p>
<pre><code class="language-bash">$ git remote remove pySpider
$ git remote add pySpider git@github.com:LittleFish0820/python-spider.git

$ git push pySpider master
Enumerating objects: 4, done.
Counting objects: 100% (4/4), done.
Delta compression using up to 4 threads
Compressing objects: 100% (2/2), done.
Writing objects: 100% (4/4), 605 bytes | 302.00 KiB/s, done.
Total 4 (delta 0), reused 0 (delta 0), pack-reused 0
To github.com:LittleFish0820/python-spider.git
 * [new branch]      master -&gt; master
</code></pre>
<p><strong>5. 克隆远程仓库到本地</strong></p>
<pre><code class="language-shell">$ git clone https://github.com/LittleFish0820/python-spider.git
Cloning into 'python-spider'...
Cloning into 'python-spider'...
remote: Enumerating objects: 4, done.
remote: Counting objects: 100% (4/4), done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 4 (delta 0), reused 4 (delta 0), pack-reused 0
Receiving objects: 100% (4/4), done.
</code></pre>
<p><strong>6. 拉取远程仓库内容</strong></p>
<pre><code class="language-bash">$ git init

$ git pull git@github.com:LittleFish0820/python-spider master
remote: Enumerating objects: 4, done.
remote: Counting objects: 100% (4/4), done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 4 (delta 0), reused 4 (delta 0), pack-reused 0
Unpacking objects: 100% (4/4), 585 bytes | 3.00 KiB/s, done.
From github.com:LittleFish0820/python-spider
 * branch            master     -&gt; FETCH_HEAD
</code></pre>
<h2 id="邀请合作伙伴">邀请合作伙伴</h2>
<figure data-type="image" tabindex="3"><img src="https://LittleFish0820.github.io/post-images/1661196867942.png" alt="" loading="lazy"></figure>
<h2 id="跨团队协作">跨团队协作</h2>
<p><code>fork</code></p>
<p><code>Pull requests</code></p>
<h2 id="免密登录">免密登录</h2>
<pre><code class="language-bash"># 进入C:\Users\Administrator
$ mkdir .ssh
$ cd .ssh/
$ ssh-keygen -t rsa -C fish@nenu.enu.cn
$ cat id_rsa.pub
</code></pre>
<p>将公钥信息添加到github账户，然后验证免密登录是否成功</p>
<pre><code class="language-bash">$ ssh -T git@github.com
Hi LittleFish0820! You've successfully authenticated, but GitHub does not provide shell access.
</code></pre>
<h1 id="idea-集成-git">IDEA 集成 Git</h1>
<h2 id="ignore忽略规则文件">.ignore忽略规则文件</h2>
<pre><code class="language-ignore"># Compiled class file
*.class

# Log file
*.log

# BlueJ files
*.ctxt

# Mobile Tools for Java (J2ME)
.mtj.tmp/

# Package Files
*.jar
*.war
*.nar
*.ear
*.zip
*.tar.gz
*.rar

# virtual machine crash logs, see 
http://www.java.com/en/download/help/error_hotspot.xml
hs_err_pid*
.classpath
.project
.settings
target
.idea
*.iml
</code></pre>
<p>在<code>.gitconfig</code>文件中引用忽略配置文件</p>
<pre><code class="language-shell">cd ~
vim .gitconfig
[user]
	name = ***
	email = ***
[core]
	excludesfile = C:/Users/***/git.ignore
</code></pre>
<h2 id="定位git程序">定位Git程序</h2>
<p><code>Settings -&gt; Version Control -&gt; Git -&gt; ./git/bin/git.exe</code></p>
<p>需要初始化本地库IDEA才能用git</p>
<ul>
<li>add</li>
<li>commit</li>
<li>branch</li>
<li>merge</li>
</ul>
<h1 id="idea-集成-github">IDEA 集成 GitHub</h1>
<p><code>Settings -&gt; Version Control -&gt; GitHub</code></p>
<p>两种登录方式：直接登录和Token令牌</p>
<ul>
<li>
<p>push</p>
</li>
<li>
<p>pull</p>
</li>
<li>
<p>clone</p>
</li>
</ul>
<h1 id="码云">码云</h1>
<p>以后如果用到了再更新</p>
<h1 id="gitlab">GitLab</h1>
<p>如果用到了再更新</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java异常]]></title>
        <id>https://LittleFish0820.github.io/post/Java_throwable/</id>
        <link href="https://LittleFish0820.github.io/post/Java_throwable/">
        </link>
        <updated>2022-08-22T02:10:10.000Z</updated>
        <summary type="html"><![CDATA[<p>本文介绍Error和Exception、自定义异常和IDEA调试方法。</p>
]]></summary>
        <content type="html"><![CDATA[<p>本文介绍Error和Exception、自定义异常和IDEA调试方法。</p>
<!-- more -->
<p><ul class="markdownIt-TOC">
<li><a href="#%E5%BC%82%E5%B8%B8%E6%9C%BA%E5%88%B6">异常机制</a></li>
<li><a href="#%E5%BC%82%E5%B8%B8%E5%88%86%E7%B1%BB">异常分类</a>
<ul>
<li><a href="#error">Error</a></li>
<li><a href="#exception">Exception</a>
<ul>
<li><a href="#runtime-exception">Runtime Exception</a></li>
<li><a href="#checked-exception">Checked Exception</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E5%BC%82%E5%B8%B8%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F">异常的处理方式</a>
<ul>
<li><a href="#%E6%8D%95%E8%8E%B7%E5%BC%82%E5%B8%B8">捕获异常</a></li>
<li><a href="#%E5%A3%B0%E6%98%8E%E5%BC%82%E5%B8%B8">声明异常</a></li>
<li><a href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%BC%82%E5%B8%B8">自定义异常</a>
<ul>
<li><a href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B9%B4%E9%BE%84%E4%B8%BA%E8%B4%9F%E6%95%B0%E7%9A%84%E5%BC%82%E5%B8%B8">自定义年龄为负数的异常</a></li>
</ul>
</li>
<li><a href="#person%E7%B1%BB">Person类</a></li>
</ul>
</li>
<li><a href="#idea-%E8%B0%83%E8%AF%95-debug">IDEA 调试 debug</a></li>
</ul>
</p>
<h1 id="异常机制">异常机制</h1>
<p>Java采用面向对象的方式处理异常</p>
<ul>
<li>抛出异常：在执行一个方法时若发生异常，则这个方法生成代表该异常的一个对象，停止当前执行路径，并把异常对象提交给JRE(Java Runtime Environment)</li>
<li>捕获异常：JRE得到该异常后，寻找相应的代码来处理该异常。JRE在方法的调用栈中查找，从生成异常的方法开始回溯，直到找到相应的异常处理代码为止。</li>
</ul>
<h1 id="异常分类">异常分类</h1>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/ddb5ed058ed64fb59e7c4f49652141d9.png" alt="继承图" loading="lazy"></figure>
<h2 id="error">Error</h2>
<p>是程序无法处理的错误，较严重。</p>
<ul>
<li>Virtual Machine Error</li>
<li>Out Of Memory Error</li>
<li>...</li>
</ul>
<p>Error发生时，Java虚拟机一般会选择线程终止。</p>
<h2 id="exception">Exception</h2>
<p>是程序本身能够处理的异常。</p>
<h3 id="runtime-exception">Runtime Exception</h3>
<p>这里异常通常是由编程错误导致，因此可以用逻辑处理来避免异常。</p>
<ul>
<li>Null Pointer Exception</li>
<li>Array Index Out Of Bounds Exception</li>
<li>Class Cast Exception</li>
<li>Arithmetic Exception 算术异常</li>
<li>Number Format Exception</li>
</ul>
<h3 id="checked-exception">Checked Exception</h3>
<p>这类异常在编译时就必须作出处理，否则无法通过编译。</p>
<ul>
<li>IO Exception</li>
<li>SQL Exception</li>
</ul>
<h1 id="异常的处理方式">异常的处理方式</h1>
<h2 id="捕获异常">捕获异常</h2>
<p><code>try-catch-finally</code></p>
<ul>
<li><code>\uFFFF</code>表示空字符</li>
<li><code>System.out.printf</code>不能输出<code>char</code></li>
<li>异常捕获顺序 子类在父类前面</li>
<li><code>finally</code>中用来关闭程序块已打开的资源，例如关闭文件流，释放数据库连接等。</li>
</ul>
<pre><code class="language-java">public class IoException {
    public static void main(String[] args) {
        FileReader fileReader = null;
        try {
            fileReader = new FileReader(&quot;input/input.txt&quot;);
            char ch = (char)fileReader.read();
            while (ch != '\uFFFF') {
                System.out.printf(&quot;&quot; + ch);
                ch = (char)fileReader.read();
            }
        } catch (FileNotFoundException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            try {
                if (fileReader != null)
                    fileReader.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }
}
</code></pre>
<h2 id="声明异常">声明异常</h2>
<p><code>readFile</code>抛出异常，<code>main</code>捕获到异常，并输出自定义语句。</p>
<pre><code class="language-java">import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.IOException;

public class Throws {
    public static void main(String[] args) {
        try {
            readFile(&quot;input/input.txt&quot;);
        } catch (FileNotFoundException e) {
            System.out.println(&quot;所需文件不存在！&quot;);
        } catch (IOException e) {
            System.out.println(&quot;文件读写错误！&quot;);
        }
    }
    public static void readFile(String fileName) throws FileNotFoundException, IOException {
        FileReader fileReader = new FileReader(fileName);
        char ch = (char)fileReader.read();
        while (ch != '\uFFFF') {
            System.out.printf(&quot;&quot; + ch);
            ch = (char)fileReader.read();
        }
        fileReader.close();
    }
}
</code></pre>
<h2 id="自定义异常">自定义异常</h2>
<h3 id="自定义年龄为负数的异常">自定义年龄为负数的异常</h3>
<pre><code class="language-java">public class IllegalAgeException extends Exception{
    IllegalAgeException() {}
    IllegalAgeException(String message) {
        super(message); // 调用父类的构造函数
    }
}
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/0701dc7cbce246488b889c83bcfcf56b.png" alt="Exception构造函数" loading="lazy"></figure>
<h2 id="person类">Person类</h2>
<pre><code class="language-java">public class Person {
    private String name;
    private int age;
    public void setName(String name) {this.name = name;};
    public void setAge(int age) throws IllegalAgeException {
        if (age &lt; 0) {
            throw new IllegalAgeException(&quot;年龄不能为负数&quot;);
        }
        this.age = age;
    };

    public static void main(String[] args)  {
        Person person = new Person();
        person.setName(&quot;张三&quot;);
        try {
            person.setAge(-24);
        } catch (Exception e){
            e.printStackTrace();
        } finally {
            System.out.println(&quot;exit&quot;);
        }
    }
}
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://img-blog.csdnimg.cn/3a4ea6b8654444c8bbe516f1a4e06aab.png" alt="自定义异常输出信息" loading="lazy"></figure>
<h1 id="idea-调试-debug">IDEA 调试 debug</h1>
<ul>
<li>添加断点</li>
<li>进入调试模式
<ul>
<li>编辑区单击右键，点击：debug</li>
<li>单击工具栏上的按钮</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java数组]]></title>
        <id>https://LittleFish0820.github.io/post/java_array/</id>
        <link href="https://LittleFish0820.github.io/post/java_array/">
        </link>
        <updated>2022-08-20T00:08:08.000Z</updated>
        <summary type="html"><![CDATA[<p>本文介绍Java数组的创建、遍历、复制，Arrays类的几种常用方法，以及优化后的冒泡排序。</p>
]]></summary>
        <content type="html"><![CDATA[<p>本文介绍Java数组的创建、遍历、复制，Arrays类的几种常用方法，以及优化后的冒泡排序。</p>
<!-- more -->
<p><ul class="markdownIt-TOC">
<li><a href="#%E6%95%B0%E7%BB%84%E6%A6%82%E8%BF%B0">数组概述</a></li>
<li><a href="#%E5%88%9B%E5%BB%BA%E6%95%B0%E7%BB%84%E5%92%8C%E5%88%9D%E5%A7%8B%E5%8C%96">创建数组和初始化</a></li>
<li><a href="#%E6%95%B0%E7%BB%84%E9%81%8D%E5%8E%86%E5%92%8C%E5%A4%8D%E5%88%B6">数组遍历和复制</a></li>
<li><a href="#javautilarrays%E7%B1%BB">Java.util.Arrays类</a>
<ul>
<li><a href="#arraystostring">Arrays.toString()</a></li>
<li><a href="#arrayssort">Arrays.sort()</a></li>
<li><a href="#arraysfill">Arrays.fill()</a></li>
</ul>
</li>
<li><a href="#%E7%94%A8%E6%95%B0%E7%BB%84%E5%AD%98%E5%82%A8%E8%A1%A8%E6%A0%BC%E6%95%B0%E6%8D%AE">用数组存储表格数据</a></li>
<li><a href="#%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F%E4%BC%98%E5%8C%96">冒泡排序(优化)</a></li>
<li><a href="#%E4%BA%8C%E5%88%86%E6%B3%95">二分法</a></li>
</ul>
</p>
<h1 id="数组概述">数组概述</h1>
<ol>
<li>长度确定</li>
<li>元素类型必须相同</li>
<li>可以存储基本数据类型和引用数据类型</li>
<li>数组变量属于引用类型</li>
</ol>
<hr>
<h1 id="创建数组和初始化">创建数组和初始化</h1>
<pre><code class="language-java">int[] arr1 = null;  // 声明数组
arr1 = new int[4];  // 给数组分配空间
int arr2[] = new int[4];
int[] arr3 = new int[] {1, 2, 3, 4};

String mat1[][] = {{&quot;Hello&quot;, &quot;Flink&quot;, &quot;Hadoop&quot;}, {&quot;Spark&quot;, &quot;Flume&quot;}};
double[] mat2[] = new double[4][];
char mat3[][] = new char[4][4];
</code></pre>
<hr>
<h1 id="数组遍历和复制">数组遍历和复制</h1>
<ol>
<li>下标遍历与增强for循环</li>
</ol>
<pre><code class="language-java">String mat[][] = {{&quot;Hello&quot;, &quot;Flink&quot;, &quot;Hadoop&quot;}, {&quot;Spark&quot;, &quot;Flume&quot;}};

for (int i = 0; i &lt; mat.length; i++) {
    for (int j = 0; j &lt; mat[i].length; j++) {
        System.out.printf(mat[i][j] + ' ');
    }
    System.out.println();
}

System.out.println(&quot;--------------------------------&quot;);

for (String[] words : mat) {
    for (String word : words) {
        System.out.printf(word + ' ');
    }
    System.out.println();
}
</code></pre>
<ol start="2">
<li>复制</li>
</ol>
<pre><code class="language-java">System.arraycopy(object src, int srcpos, object dest, int destpos, int length)
String mat[][] = {{&quot;Hello&quot;, &quot;Flink&quot;, &quot;Hadoop&quot;}, {&quot;Spark&quot;, &quot;Flume&quot;}};
String matCopy[][] = new String[2][];
System.arraycopy(mat, 0, matCopy, 0, 2);
System.out.println(matCopy.toString());
System.out.println(Arrays.toString(matCopy));
System.out.println(Arrays.toString(matCopy[0]));
System.out.println(Arrays.toString(matCopy[1]));
// ---------------------------------------------
[[Ljava.lang.String;@14ae5a5
[[Ljava.lang.String;@7f31245a, [Ljava.lang.String;@6d6f6e28]
[Hello, Flink, Hadoop]
[Spark, Flume]
</code></pre>
<hr>
<h1 id="javautilarrays类">Java.util.Arrays类</h1>
<h2 id="arraystostring">Arrays.toString()</h2>
<p>打印数组元素的值，若数组元素还是引用类型，则打印的仍然是引用的值<br>
<code>Arrays.toString()</code>方法是<code>Arrays</code>类的静态方法</p>
<pre><code class="language-java">public static String toString(Object[] a) {
    if (a == null)
        return &quot;null&quot;;

    int iMax = a.length - 1;
    if (iMax == -1)
        return &quot;[]&quot;;

    StringBuilder b = new StringBuilder();
    b.append('[');
    for (int i = 0; ; i++) {
        b.append(String.valueOf(a[i]));
        if (i == iMax)
            return b.append(']').toString();
        b.append(&quot;, &quot;);
    }
}
</code></pre>
<h2 id="arrayssort">Arrays.sort()</h2>
<ol>
<li>默认排序方式</li>
</ol>
<pre><code class="language-java">int arr[] = {1, 9, 8, 2, 3, 7, 6, 5, 4};
Arrays.sort(arr);
System.out.println(Arrays.toString(arr));
</code></pre>
<ol start="2">
<li>自定义排序规则 (Comparable接口)</li>
</ol>
<pre><code class="language-java">public class Person implements Comparable{
    private String name;
    private int age;
    public Person(String name, int age) {
        this.name = name;
        this.age = age;
    }

    @Override
    public String toString() {
        return &quot;Person{&quot; +
                &quot;name='&quot; + name + '\'' +
                &quot;, age=&quot; + age +
                '}';
    }

    @Override
    public int compareTo(Object o) {
        Person person = (Person) o;
        if (this.age &lt; person.age) {
            return 1;
        }
        if (this.age &gt; person.age) {
            return -1;
        }
        return 0;
    }
}
Person p1 = new Person(&quot;Amy&quot;, 24);
Person p2 = new Person(&quot;Tom&quot;, 22);
Person p3 = new Person(&quot;Anna&quot;, 23);
Person[] people = {p1, p2, p3};
Arrays.sort(people);
System.out.println(Arrays.toString(people));
</code></pre>
<h2 id="arraysfill">Arrays.fill()</h2>
<p>左闭右开</p>
<pre><code class="language-java">int arr[] = new int[] {1, 2, 3, 4, 5};
Arrays.fill(arr, 2, 4, 6);
System.out.println(Arrays.toString(arr));
</code></pre>
<hr>
<h1 id="用数组存储表格数据">用数组存储表格数据</h1>
<table>
<thead>
<tr>
<th>ID</th>
<th>Name</th>
<th>Age</th>
<th>Gender</th>
</tr>
</thead>
<tbody>
<tr>
<td>1001</td>
<td>Amy</td>
<td>22</td>
<td>F</td>
</tr>
<tr>
<td>1002</td>
<td>Tom</td>
<td>23</td>
<td>M</td>
</tr>
<tr>
<td>1003</td>
<td>John</td>
<td>24</td>
<td>M</td>
</tr>
</tbody>
</table>
<pre><code class="language-java">Object[] p1 = {1001, &quot;Amy&quot;, 21, 'F'};
Object[] p2 = {1002, &quot;Tom&quot;, 22, 'M'};
Object[] p3 = {1003, &quot;John&quot;, 23, 'M'};
Object[][] emps = new Object[3][];
emps[0] = p1;
emps[1] = p2;
emps[2] = p3;
for (Object[] person : emps) {
    System.out.println(Arrays.toString(person));
}
</code></pre>
<hr>
<h1 id="冒泡排序优化">冒泡排序(优化)</h1>
<ul>
<li>若不用static关键字，则需要创建一个BubbleSort对象，再调用bubbleSort方法</li>
<li>为什么外层是n-1次循环？因为一次循环排好一个数，n-1次循环排好n-1个数，最后一个数则自然排好。</li>
<li>为什么内层是n-1-i次循环？n个数比较n-1次。</li>
<li>当内部没有发生比较时，说明已经排序好了。</li>
</ul>
<pre><code class="language-java">public class BubbleSort {
    public static void main(String[] args) {
        int[] arr = {3, 1, 6, 2, 9, 0, 7, 4, 5, 8};
        bubbleSort(arr);
        System.out.println(Arrays.toString(arr));
    }
    public static void bubbleSort(int[] arr) {
        int n = arr.length;
        for (int i = 0; i &lt; n - 1; i++) {
            boolean flag = true;
            for (int j = 0; j &lt; n - i - 1; j++) {
                if (arr[j] &gt; arr[j + 1]) {
                    swap(arr, j, j + 1);
                    flag = false;
                }
            }
            if (flag) break;
        }
    }
    public static void swap(int[] arr, int i, int j) {
        int temp = arr[i];
        arr[i] = arr[j];
        arr[j] = temp;
    }
}
</code></pre>
<h1 id="二分法">二分法</h1>
<p><code>Arrays.binarySearch(arr, target)</code></p>
<ul>
<li>找到，返回正数，索引从零开始；</li>
<li>没找到，返回负数，索引从负一开始。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Git基础]]></title>
        <id>https://LittleFish0820.github.io/post/git_produce/</id>
        <link href="https://LittleFish0820.github.io/post/git_produce/">
        </link>
        <updated>2022-08-19T11:19:19.000Z</updated>
        <summary type="html"><![CDATA[<p></p>
<p>本文介绍Git原理和本地模式的命令基本操作。</p>
]]></summary>
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC">
<li><a href="#git-%E6%A6%82%E8%BF%B0">Git 概述</a>
<ul>
<li><a href="#%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6revision-control">版本控制(Revision Control)</a></li>
<li><a href="#git-%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6">Git 工作机制</a></li>
<li><a href="#git-%E5%92%8C%E4%BB%A3%E7%A0%81%E6%89%98%E7%AE%A1%E4%B8%AD%E5%BF%83">Git 和代码托管中心</a></li>
</ul>
</li>
<li><a href="#git-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4">GIt 常用命令</a>
<ul>
<li><a href="#%E8%AE%BE%E7%BD%AE%E7%94%A8%E6%88%B7%E7%AD%BE%E5%90%8D">设置用户签名</a></li>
<li><a href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E6%9C%AC%E5%9C%B0%E4%BB%93%E5%BA%93">初始化本地仓库</a></li>
<li><a href="#%E6%9F%A5%E7%9C%8B%E6%9C%AC%E5%9C%B0%E5%BA%93%E7%8A%B6%E6%80%81">查看本地库状态</a></li>
<li><a href="#%E6%B7%BB%E5%8A%A0%E6%9A%82%E5%AD%98%E5%8C%BA">添加暂存区</a></li>
<li><a href="#%E6%8F%90%E4%BA%A4%E6%9C%AC%E5%9C%B0%E5%BA%93">提交本地库</a></li>
<li><a href="#%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6modified">修改文件(modified)</a></li>
<li><a href="#%E5%8E%86%E5%8F%B2%E7%89%88%E6%9C%AC">历史版本</a>
<ul>
<li><a href="#%E6%9F%A5%E7%9C%8B%E5%8E%86%E5%8F%B2%E7%89%88%E6%9C%AC">查看历史版本</a></li>
<li><a href="#%E7%89%88%E6%9C%AC%E7%A9%BF%E6%A2%AD">版本穿梭</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#git-%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C">Git 分支操作</a>
<ul>
<li><a href="#%E6%9F%A5%E7%9C%8B%E5%88%86%E6%94%AF">查看分支</a></li>
<li><a href="#%E5%88%9B%E5%BB%BA%E5%88%86%E6%94%AF">创建分支</a></li>
<li><a href="#%E4%BF%AE%E6%94%B9%E5%88%86%E6%94%AF%E9%A1%B9%E7%9B%AE">修改分支项目</a></li>
<li><a href="#%E5%88%87%E6%8D%A2%E5%88%86%E6%94%AF">切换分支</a></li>
<li><a href="#%E5%90%88%E5%B9%B6%E5%88%86%E6%94%AF">合并分支</a></li>
</ul>
</li>
<li><a href="#%E4%B8%8B%E5%9B%9E%E6%9B%B4%E7%B2%BE%E5%BD%A9">下回更精彩</a></li>
</ul>
</p>
<p>本文介绍Git原理和本地模式的命令基本操作。</p>
<!-- more -->
<h1 id="git-概述">Git 概述</h1>
<p>Git 是一个免费的、开源的<mark>分布式版本控制系统</mark>，可以快速高效地处理从小型到大型的各种项目。</p>
<p>它具有廉价的本地库，方便的暂存区域和多个工作流分支等特性。其性能优于 Subversion、CVS、Perforce 和 ClearCase 等版本控制工具。</p>
<h2 id="版本控制revision-control">版本控制(Revision Control)</h2>
<p><strong>1. What</strong></p>
<p>版本控制是一种记录文件内容变化，以便将来查阅特定版本修订情况的系统。</p>
<p>版本控制其实最重要的是可以记录文件修改历史记录，从而让用户能够查看历史版本，方便版本切换。</p>
<p><strong>2. Why</strong></p>
<p>从个人开发过渡到团队协作。团队协作如果没有版本控制，会出现很多问题。</p>
<figure data-type="image" tabindex="1"><img src="https://LittleFish0820.github.io/post-images/1661096141734.jpg" alt="版本控制优势" loading="lazy"></figure>
<p><strong>3. 版本控制工具</strong></p>
<ul>
<li>
<p>集中式</p>
<ul>
<li>SVN（Subversion），CVS（Concurrent Versions System），VSS，......</li>
<li>优点：权限掌控；管理容易。</li>
<li>缺点：所有的版本数据都存在服务器上，不连网就无法看到历史版本，容易发生单点故障</li>
</ul>
</li>
<li>
<p>分布式</p>
<ul>
<li>Git、Mercurial、Bazaar、Darcs、……</li>
<li>优点：服务器断网的情况下也可以进行开发（因为版本控制是在本地进行的）；每个客户端保存的也都是整个完整的项目（包含历史记录，更加安全）</li>
<li>缺点：安全隐患</li>
</ul>
</li>
</ul>
<h2 id="git-工作机制">Git 工作机制</h2>
<figure data-type="image" tabindex="2"><img src="https://LittleFish0820.github.io/post-images/1661096173963.jpg" alt="Git工作机制" loading="lazy"></figure>
<h2 id="git-和代码托管中心">Git 和代码托管中心</h2>
<p>代码托管中心是基于网络服务器的<mark>远程代码仓库</mark>，简称<mark>远程库</mark>。</p>
<ul>
<li>Local Area Network
<ul>
<li>GitLab</li>
</ul>
</li>
<li>Internet
<ul>
<li>GitHub</li>
<li>Gitee</li>
</ul>
</li>
</ul>
<h1 id="git-常用命令">GIt 常用命令</h1>
<h2 id="设置用户签名">设置用户签名</h2>
<pre><code class="language-shell">Administrator@LittleFish MINGW64 /f/LittleFish/GitHub/git-demo
$ git config --global user.name fish

Administrator@LittleFish MINGW64 /f/LittleFish/GitHub/git-demo
$ git config --global user.email fish@nenu.edu.cn

Administrator@LittleFish MINGW64 /f/LittleFish/GitHub/git-demo
$ cat ~/.gitconfig
[user]
        name = fish
        email = fish@nenu.edu.cn
</code></pre>
<p>用户签名只为区分用户身份，与GitHub账号无关。</p>
<h2 id="初始化本地仓库">初始化本地仓库</h2>
<pre><code class="language-bash">Administrator@LittleFish MINGW64 /f/LittleFish/GitHub/git-demo
$ git init
Initialized empty Git repository in F:/LittleFish/GitHub/git-demo/.git/
</code></pre>
<p><code>git-demo</code>目录下出现<code>.git</code>文件夹</p>
<h2 id="查看本地库状态">查看本地库状态</h2>
<p><strong>1. 首次查看</strong></p>
<pre><code class="language-bash">Administrator@LittleFish MINGW64 /f/LittleFish/GitHub/git-demo (master)
$ git status
On branch master

No commits yet

nothing to commit (create/copy files and use &quot;git add&quot; to track)
</code></pre>
<p><strong>2. create files</strong></p>
<p>如无特别说明，以后都在<code>git-demo</code>目录下操作</p>
<pre><code class="language-bash">$ vim hellogit.txt
Hello git!
Hello World!
</code></pre>
<p><strong>3. 再次查看</strong></p>
<pre><code class="language-bash">$ git status
On branch master

No commits yet

Untracked files:
  (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed)
        hellogit.txt   # 红色高亮

nothing added to commit but untracked files present (use &quot;git add&quot; to track)
</code></pre>
<p>表示<code>hellogit.txt</code>在工作区中，但未被追踪，即还没有提交到暂存区。</p>
<h2 id="添加暂存区">添加暂存区</h2>
<p><strong>1. 将工作区的文件添加到暂存区</strong></p>
<pre><code class="language-bash">$ git add hellogit.txt
</code></pre>
<p>取消暂存区</p>
<pre><code class="language-bash">$ git reset hellogit.txt
</code></pre>
<p><strong>2. 查看状态</strong></p>
<pre><code class="language-bash">$ git status
On branch master

No commits yet

Changes to be committed:
  (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage)
        new file:   hellogit.txt   # 绿色高亮
</code></pre>
<p>暂存区有一个新文件，等待被提交到本地库。</p>
<h2 id="提交本地库">提交本地库</h2>
<p><strong>1. 将暂存区的文件提交到本地库</strong></p>
<pre><code class="language-bash">$ git commit -m &quot;Hello Git! My fist commit.&quot; hellogit.txt
[master (root-commit) c7df131] Hello Git! My fist commit.
 1 file changed, 2 insertions(+)
 create mode 100644 hellogit.txt
</code></pre>
<p><strong>2. 查看状态</strong></p>
<pre><code class="language-bash">$ git status
On branch master
nothing to commit, working tree clean
</code></pre>
<blockquote>
<p>注意：可以与<code>git init</code>后的<code>git status</code>比较</p>
</blockquote>
<h2 id="修改文件modified">修改文件(modified)</h2>
<pre><code class="language-bash">$ vim hellogit.txt
Hello git! My name is fish.
Hello World!
</code></pre>
<p><strong>1. 查看状态</strong></p>
<pre><code class="language-bash">$ git status
On branch master
Changes not staged for commit:
  (use &quot;git add &lt;file&gt;...&quot; to update what will be committed)
  (use &quot;git restore &lt;file&gt;...&quot; to discard changes in working directory)
        modified:   hellogit.txt   // 红色高亮

no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)
</code></pre>
<p><strong>2. 添加暂存区并查看状态</strong></p>
<pre><code class="language-bash">$ git add hellogit.txt

$ git status
On branch master
Changes to be committed:
  (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage)
        modified:   hellogit.txt    // 绿色高亮
</code></pre>
<p><strong>3. 添加本地库并查看状态</strong></p>
<pre><code class="language-bash">$ git commit -m &quot;second commit&quot; hellogit.txt
[master 9271949] second commit
 1 file changed, 1 insertion(+), 1 deletion(-)

$ git status
On branch master
nothing to commit, working tree clean
</code></pre>
<h2 id="历史版本">历史版本</h2>
<h3 id="查看历史版本">查看历史版本</h3>
<p><strong>1. git reflog 查看版本信息</strong></p>
<pre><code class="language-bash">$ git reflog
9271949 (HEAD -&gt; master) HEAD@{0}: commit: second commit
c7df131 HEAD@{1}: commit (initial): Hello Git! My fist commit.
</code></pre>
<p><strong>2. git log 查看版本详细信息</strong></p>
<p>能看到完整版本号、用户名、用户邮箱和时间。</p>
<pre><code class="language-bash">$ git log
commit 92719490c48da9ba475620f8a884fc5448c86f40 (HEAD -&gt; master)
Author: fish &lt;fish@nenu.edu.cn&gt;
Date:   Sun Aug 21 14:49:43 2022 +0800

    second commit

commit c7df131a47a605276c3b2f0bf1bfbe226b1b79b6
Author: fish &lt;fish@nenu.edu.cn&gt;
Date:   Sun Aug 21 14:42:35 2022 +0800

    Hello Git! My fist commit.
</code></pre>
<h3 id="版本穿梭">版本穿梭</h3>
<p><code>git reset --hard 版本号</code></p>
<p><strong>1. 今穿古</strong></p>
<ul>
<li>版本号只要唯一，可以只是前缀</li>
<li>注意<code>HEAD</code>指针指向</li>
<li>文件已经是第一版本的内容</li>
</ul>
<pre><code class="language-shell">$ git reset --hard c7df131
HEAD is now at c7df131 Hello Git! My fist commit.

$ git reflog
c7df131 (HEAD -&gt; master) HEAD@{0}: reset: moving to c7df131
9271949 HEAD@{1}: commit: second commit
c7df131 (HEAD -&gt; master) HEAD@{2}: commit (initial): Hello Git! My fist commit.

$ cat hellogit.txt
Hello git!
Hello World!
</code></pre>
<p><strong>2. 古穿今</strong></p>
<pre><code class="language-shell">$ git reset --hard 9271949
HEAD is now at 9271949 second commit

$ git reflog
9271949 (HEAD -&gt; master) HEAD@{0}: reset: moving to 9271949
c7df131 HEAD@{1}: reset: moving to c7df131
9271949 (HEAD -&gt; master) HEAD@{2}: commit: second commit
c7df131 HEAD@{3}: commit (initial): Hello Git! My fist commit.

$ cat hellogit.txt
Hello git! My name is fish.
Hello World!
</code></pre>
<p><strong>3. 版本穿梭原理</strong></p>
<p>在不改变分支的前提下，<code>HEAD-&gt;master-&gt;</code>保持一体。</p>
<figure data-type="image" tabindex="3"><img src="https://LittleFish0820.github.io/post-images/1661096208765.jpg" alt="版本穿梭原理" loading="lazy"></figure>
<h1 id="git-分支操作">Git 分支操作</h1>
<p>在版本控制过程中，同时推进多个任务，我们就可以创建每个任务的单独分支。使用分支意味着程序员可以把自己的工作从开发主线上分离开来，开发自己分支的时候，不会影响主线分支的运行。（分支底层其实也是指针的引用：<code>HEAD</code>和分支两个指针）</p>
<ul>
<li>同时并行推进多个功能开发，提高开发效率。</li>
<li>各个分支在开发过程中，如果某一个分支开发失败，不会对其他分支有任何影响。失败的分支可以重开。</li>
</ul>
<h2 id="查看分支">查看分支</h2>
<pre><code class="language-shell">$ git branch -v
* master 9271949 second commit   
</code></pre>
<p><code>*</code>代表当前所在的分支是<code>master</code>，其中<code>master</code>绿色高亮</p>
<h2 id="创建分支">创建分支</h2>
<pre><code class="language-shell">$ git branch hot-fix

$ git branch -v
  hot-fix 9271949 second commit
* master  9271949 second commit
</code></pre>
<h2 id="修改分支项目">修改分支项目</h2>
<p><strong>1. 在master分支上做修改</strong></p>
<pre><code class="language-shell">$ vim hellogit.txt
Hello Git!
Branch is master.
</code></pre>
<p><strong>2. 添加暂存区，提交本地库</strong></p>
<pre><code class="language-shell">$ git add hellogit.txt

$ git commit -m &quot;third commit&quot; hellogit.txt
[master d721067] third commit
 1 file changed, 2 insertions(+), 2 deletions(-)
</code></pre>
<p><strong>3. 查看分支</strong></p>
<pre><code class="language-bash">$ git branch -v
  hot-fix 9271949 second commit
* master  d721067 third commit
</code></pre>
<h2 id="切换分支">切换分支</h2>
<p><strong>1. 切换分支并查看分支</strong></p>
<pre><code class="language-shell">$ git checkout hot-fix
Switched to branch 'hot-fix'

$ git branch -v
* hot-fix 9271949 second commit
  master  d721067 third commit
</code></pre>
<p><strong>2. 查看分支项目文件</strong></p>
<pre><code class="language-shell">$ cat hellogit.txt
Hello git! My name is fish.
Hello World!
</code></pre>
<p>可以发现修改<code>master</code>分支并提交本地库，<code>hot-fix</code>分支不受影响。</p>
<h2 id="合并分支">合并分支</h2>
<p><strong>1. 在hot-fix分支上合并master分支</strong></p>
<pre><code class="language-bash">.../git-demo (hot-fix)
$ git merge master
Updating 9271949..d721067
Fast-forward
 hellogit.txt | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)
 
$ cat hellogit.txt
Hello Git!
Branch is master.
</code></pre>
<p>因为<code>hot-fix</code>无变化分支，<code>master</code>分支有修改，默认跟随<code>master</code>分支。</p>
<pre><code class="language-bash">$ git branch -v
* hot-fix d721067 third commit
  master  d721067 third commit
</code></pre>
<blockquote>
<p>注意：合并<code>master</code>分支后<code>master</code>并不会消失。</p>
</blockquote>
<p><strong>2. 产生冲突</strong></p>
<pre><code class="language-bash"># 修改hot-fix分支并提交本地库
.../git-demo (hot-fix)
$ vim hellogit.txt
Branch is hot-fix.

$ git add hellogit.txt

$ git commit -m &quot;hot-fix forth commit&quot; hellogit.txt
[hot-fix 86219e8] hot-fix forth commit
 1 file changed, 1 insertion(+), 2 deletions(-)

# 切换到master分支并修改分支
$ vim hellogit.txt
Branch is master.

$ git add hellogit.txt

$ git commit -m &quot;master forth commit&quot; hellogit.txt
[master c97ad0b] master forth commit
 1 file changed, 1 deletion(-)
</code></pre>
<p><strong>3. 解决冲突</strong></p>
<pre><code class="language-shell"># 在master分支合并hot-fix分支
$ git merge hot-fix
Auto-merging hellogit.txt
CONFLICT (content): Merge conflict in hellogit.txt
Automatic merge failed; fix conflicts and then commit the result.

# 查看分支状态 MERGING
.../git-demo (master|MERGING)
$ git status
On branch master
You have unmerged paths.
  (fix conflicts and run &quot;git commit&quot;)
  (use &quot;git merge --abort&quot; to abort the merge)

Unmerged paths:
  (use &quot;git add &lt;file&gt;...&quot; to mark resolution)
        both modified:   hellogit.txt  # 红色高亮

no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)
</code></pre>
<p>合并分支时，两个分支在<strong>同一个文件的同一个位置</strong>有两套完全不同的修改。Git 无法替我们决定使用哪一个。必须<strong>人为决定</strong>新代码内容。</p>
<pre><code class="language-shell">$ vim hellogit.txt
&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD
Branch is master.
=======
Branch is hot-fix.
&gt;&gt;&gt;&gt;&gt;&gt;&gt; hot-fix

# 人为修改好后，添加本地库，不能带文件名
.../git-demo (master|MERGING)
$ cat hellogit.txt
Branch: master hot-fix

$ git add hellogit.txt

$ git commit -m &quot;merge fifth commit&quot; hellogit.txt
fatal: cannot do a partial commit during a merge.
</code></pre>
<p>提交本地库成功后，<code>MERGING</code>消失</p>
<pre><code class="language-bash">.../git-demo (master|MERGING)
$ git commit -m &quot;merge fifth commit&quot;
[master 33e20d2] merge fifth commit

.../git-demo (master)
$ git status
On branch master
nothing to commit, working tree clean
</code></pre>
<h1 id="下回更精彩">下回更精彩</h1>
<p>本文介绍了Git原理和单机模式的一些基操，下回讲解Git如何多人运动。</p>
]]></content>
    </entry>
</feed>